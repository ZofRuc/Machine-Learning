# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i8luBiBxp7sGh77h0t3jm7bHi0mKbwdn
"""

from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

iris = load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

knn = KNeighborsClassifier(n_neighbors=3)

knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

print("Dokładność klasyfikacji:", accuracy)

#Boston

from sklearn import datasets
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import pandas as pd
import numpy as np

pip install --upgrade scikit-learn

#Wine

from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

wine = load_wine()

X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=42)

knn = KNeighborsClassifier(n_neighbors=5)

knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)

print("Dokładność klasyfikacji KNN na zbiorze danych Wine: {:.2f}%".format(accuracy * 100))

#Diabet

from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neighbors import KNeighborsRegressor

# wczytanie zbiór danych Diabetes
diabetes = load_diabetes()

# podział zbiór danych na zestaw uczący i zestaw testowy
X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=42)

# ustalenie zakres parametrów K i wag
params = {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance']}

# stworzenie obiekt klasyfikatora KNN
knn = KNeighborsRegressor()

# stworzenie obiekt przeszukiwania siatki (przyjmuje jako argumenty stworzony wcześniej klasyfikator KNN oraz zestaw parametrów params do przetestowania)
grid_search = GridSearchCV(knn, params, cv=5)

# dopasowanie model do danych uczących i przetestuj różne kombinacje parametrów (różne kombinacje parametrów)
grid_search.fit(X_train, y_train)

#W wyniku wywołania funkcji best_params_ otrzymujemy najlepszą kombinację parametrów, a funkcja best_score_ zwraca dokładność klasyfikacji dla tej kombinacji
print("Najlepsza kombinacja parametrów: ", grid_search.best_params_)
print("Dokładność klasyfikacji: {:.2f}%".format(grid_search.best_score_ * 100))