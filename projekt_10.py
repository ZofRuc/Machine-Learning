# -*- coding: utf-8 -*-
"""projekt_10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wumk5uvO-bmVA2Ic6FOK-epI7x8r6b8Q
"""

import cv2

# Ścieżki do zdjęć
image1_path = "legitymacja.jpg"
image2_path = "zdjecie2.jpg"

def compare_images(image1_path, image2_path):
    # Wczytaj oba zdjęcia
    image1 = cv2.imread(image1_path)
    image2 = cv2.imread(image2_path)

    # Inicjalizacja detektora twarzy
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Wykryj twarze na obu zdjęciach
    faces1 = face_cascade.detectMultiScale(image1, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    faces2 = face_cascade.detectMultiScale(image2, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # Jeśli na obu zdjęciach znaleziono dokładnie jedną twarz
    if len(faces1) == 1 and len(faces2) == 1:
        # Pobierz współrzędne twarzy
        x1, y1, w1, h1 = faces1[0]
        x2, y2, w2, h2 = faces2[0]

        # Wytnij obszary z twarzami
        face1 = image1[y1:y1+h1, x1:x1+w1]
        face2 = image2[y2:y2+h2, x2:x2+w2]

        # Porównaj obszary twarzy
        result = cv2.matchTemplate(face1, face2, cv2.TM_CCOEFF_NORMED)
        similarity = result[0][0]

        # Wyświetl podobieństwo
        print("Podobieństwo twarzy: {:.2f}".format(similarity))
    else:
        print("Nie znaleziono dokładnie jednej twarzy na obu zdjęciach.")


# Porównaj oba zdjęcia
compare_images(image1_path, image2_path)

!apt-get update
!apt-get install -y build-essential cmake
!apt-get install -y libopenblas-dev liblapack-dev 
!apt-get install -y libx11-dev libgtk-3-dev
!pip install dlib

import dlib
from google.colab.patches import cv2_imshow

# Ścieżka do pliku z modelem do detekcji twarzy
face_detector_model_path = "shape_predictor_68_face_landmarks.dat"

# Ścieżka do zdjęcia
image_path = "legitymacja.jpg"

# Wczytanie obrazu
image = cv2.imread(image_path)

# Inicjalizacja detektora twarzy
face_detector = dlib.get_frontal_face_detector()

# Wczytanie modelu do wykrywania kluczowych punktów twarzy
landmark_predictor = dlib.shape_predictor(face_detector_model_path)

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)
    
    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Ścieżka do pliku z modelem do detekcji twarzy
face_detector_model_path = "shape_predictor_68_face_landmarks.dat"

# Ścieżka do zdjęcia
image_path = "zdjecie2.jpg"

# Wczytanie obrazu
image = cv2.imread(image_path)

# Inicjalizacja detektora twarzy
face_detector = dlib.get_frontal_face_detector()

# Wczytanie modelu do wykrywania kluczowych punktów twarzy
landmark_predictor = dlib.shape_predictor(face_detector_model_path)

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)
    
    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

import urllib.request
import numpy as np



# Wczytanie obrazów z różnych źródeł

# Zdjęcie 1 - z Wikipedii
url_1 = 'https://pl.wikipedia.org/wiki/Johnny_Depp#/media/Plik:Johnny_Depp_2020.jpg'

# Zdjęcie 2 - z oficjalnego konta Instagram Johnny'ego Deppa
url_2 = 'https://pl.wikipedia.org/wiki/Johnny_Depp#/media/Plik:JohnnyDeppApr2011.jpg'

# Wczytanie obrazów bezpośrednio z URL
image_data_1 = urllib.request.urlopen(url_1).read()
image_data_2 = urllib.request.urlopen(url_2).read()

image_1 = cv2.imdecode(np.asarray(bytearray(image_data_1), dtype=np.uint8), cv2.IMREAD_COLOR)
image_2 = cv2.imdecode(np.asarray(bytearray(image_data_2), dtype=np.uint8), cv2.IMREAD_COLOR)

# Wyświetlenie porównywanych zdjęć
cv2_imshow(image_1)
cv2_imshow(image_2)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Ścieżka do pliku z modelem do detekcji twarzy
face_detector_model_path = "shape_predictor_68_face_landmarks.dat"

# Ścieżka do zdjęcia
image_path = "zdjecie3.png"

# Wczytanie obrazu
image = cv2.imread(image_path)

# Inicjalizacja detektora twarzy
face_detector = dlib.get_frontal_face_detector()

# Wczytanie modelu do wykrywania kluczowych punktów twarzy
landmark_predictor = dlib.shape_predictor(face_detector_model_path)

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)
    
    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Ścieżka do pliku z modelem do detekcji twarzy
face_detector_model_path = "shape_predictor_68_face_landmarks.dat"

# Ścieżka do zdjęcia
image_path = "zdjecie4.png"

# Wczytanie obrazu
image = cv2.imread(image_path)

# Inicjalizacja detektora twarzy
face_detector = dlib.get_frontal_face_detector()

# Wczytanie modelu do wykrywania kluczowych punktów twarzy
landmark_predictor = dlib.shape_predictor(face_detector_model_path)

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)
    
    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Ścieżki do zdjęć
image1_path = "zdjecie2.jpg"
image2_path = "zdjecie4.png"

def compare_images(image1_path, image2_path):
    # Wczytaj oba zdjęcia
    image1 = cv2.imread(image1_path)
    image2 = cv2.imread(image2_path)

    # Inicjalizacja detektora twarzy
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Wykryj twarze na obu zdjęciach
    faces1 = face_cascade.detectMultiScale(image1, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    faces2 = face_cascade.detectMultiScale(image2, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # Jeśli na obu zdjęciach znaleziono dokładnie jedną twarz
    if len(faces1) == 1 and len(faces2) == 1:
        # Pobierz współrzędne twarzy
        x1, y1, w1, h1 = faces1[0]
        x2, y2, w2, h2 = faces2[0]

        # Wytnij obszary z twarzami
        face1 = image1[y1:y1+h1, x1:x1+w1]
        face2 = image2[y2:y2+h2, x2:x2+w2]

        # Porównaj obszary twarzy
        result = cv2.matchTemplate(face1, face2, cv2.TM_CCOEFF_NORMED)
        similarity = result[0][0]

        # Wyświetl podobieństwo
        print("Podobieństwo twarzy: {:.2f}".format(similarity))
    else:
        print("Nie znaleziono dokładnie jednej twarzy na obu zdjęciach.")


# Porównaj oba zdjęcia
compare_images(image1_path, image2_path)

# Ścieżki do zdjęć
image1_path = "zdjecie6.png"
image2_path = "zdjecie8.png"

def compare_images(image1_path, image2_path):
    # Wczytaj oba zdjęcia
    image1 = cv2.imread(image1_path)
    image2 = cv2.imread(image2_path)

    # Inicjalizacja detektora twarzy
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Wykryj twarze na obu zdjęciach
    faces1 = face_cascade.detectMultiScale(image1, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    faces2 = face_cascade.detectMultiScale(image2, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # Jeśli na obu zdjęciach znaleziono dokładnie jedną twarz
    if len(faces1) == 1 and len(faces2) == 1:
        # Pobierz współrzędne twarzy
        x1, y1, w1, h1 = faces1[0]
        x2, y2, w2, h2 = faces2[0]

        # Wytnij obszary z twarzami
        face1 = image1[y1:y1+h1, x1:x1+w1]
        face2 = image2[y2:y2+h2, x2:x2+w2]

        # Porównaj obszary twarzy
        result = cv2.matchTemplate(face1, face2, cv2.TM_CCOEFF_NORMED)
        similarity = result[0][0]

        # Wyświetl podobieństwo
        print("Podobieństwo twarzy: {:.2f}".format(similarity))
    else:
        print("Nie znaleziono dokładnie jednej twarzy na obu zdjęciach.")


# Porównaj oba zdjęcia
compare_images(image1_path, image2_path)

# Ścieżka do pliku z modelem do detekcji twarzy
face_detector_model_path = "shape_predictor_68_face_landmarks.dat"

# Ścieżka do zdjęcia
image_path = "zdjecie8.png"

# Wczytanie obrazu
image = cv2.imread(image_path)

# Inicjalizacja detektora twarzy
face_detector = dlib.get_frontal_face_detector()

# Wczytanie modelu do wykrywania kluczowych punktów twarzy
landmark_predictor = dlib.shape_predictor(face_detector_model_path)

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)
    
    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Ścieżka do pliku z modelem do detekcji twarzy
face_detector_model_path = "shape_predictor_68_face_landmarks.dat"

# Ścieżka do zdjęcia
image_path = "zdjecie7.png"

# Wczytanie obrazu
image = cv2.imread(image_path)

# Inicjalizacja detektora twarzy
face_detector = dlib.get_frontal_face_detector()

# Wczytanie modelu do wykrywania kluczowych punktów twarzy
landmark_predictor = dlib.shape_predictor(face_detector_model_path)

# Konwersja obrazu na skalę szarości
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Wykrywanie twarzy na obrazie
faces = face_detector(gray_image)

# Dla każdej znalezionej twarzy
for face in faces:
    # Wykrywanie kluczowych punktów twarzy
    landmarks = landmark_predictor(gray_image, face)
    
    # Rysowanie prostokątu wokół twarzy
    x, y, w, h = face.left(), face.top(), face.width(), face.height()
    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)
    
    # Rysowanie kluczowych punktów na twarzy
    for i in range(68):
        x_point = landmarks.part(i).x
        y_point = landmarks.part(i).y
        cv2.circle(image, (x_point, y_point), 2, (0, 0, 255), -1)

# Wyświetlanie obrazu z zaznaczoną twarzą i kluczowymi punktami
cv2_imshow(image)
cv2.waitKey(0)
cv2.destroyAllWindows()